/// An example of a backward pass of a linear regression model.
/// Generated by backprop.ipynb.
module {
	func.func @backward(%v0: memref<10x1xf32>,
		%v1: memref<1x1xf32>,
		%v3: memref<16x1xf32>,
		%v2: memref<16x10xf32>) -> (memref<10x1xf32>, memref<1x1xf32>) {
		%zero = arith.constant 0 : index
		%v4 = memref.alloc() : memref<16x1xf32>
		affine.for %arg0 = 0 to 16 {
			affine.for %arg1 = 0 to 1 {
				%s5 = arith.constant 0.0 : f32
				memref.store %s5, %v4[%arg0, %arg1] : memref<16x1xf32>
				affine.for %arg2 = 0 to 10 {
					%s0 = memref.load %v4[%arg0, %arg1] : memref<16x1xf32>
					%s1 = memref.load %v2[%arg0, %arg2] : memref<16x10xf32>
					%s2 = memref.load %v0[%arg2, %arg1] : memref<10x1xf32>
					%s3 = arith.mulf %s1, %s2 : f32
					%s4 = arith.addf %s0, %s3 : f32
					memref.store %s4, %v4[%arg0, %arg1] : memref<16x1xf32>
				}
			}
		}

		%v5 = memref.alloc() : memref<16x1xf32>
		affine.for %arg0 = 0 to 16 {
			affine.for %arg1 = 0 to 1 {
				%s0 = memref.load %v4[%arg0, %zero] : memref<16x1xf32>
				%s1 = memref.load %v1[%zero, %zero] : memref<1x1xf32>
				%s2 = arith.addf %s0, %s1 : f32 
				memref.store %s2, %v5[%arg0, %zero] : memref<16x1xf32>
			}
		}

		%v6 = memref.alloc() : memref<16x1xf32>
		affine.for %arg0 = 0 to 16 {
			affine.for %arg1 = 0 to 1 {
				%s0 = memref.load %v5[%arg0, %zero] : memref<16x1xf32>
				%s1 = memref.load %v3[%arg0, %zero] : memref<16x1xf32>
				%s2 = arith.subf %s0, %s1 : f32 
				memref.store %s2, %v6[%arg0, %zero] : memref<16x1xf32>
			}
		}

		%v7 = memref.alloc() : memref<16x1xf32>
		affine.for %arg0 = 0 to 16 {
			affine.for %arg1 = 0 to 1 {
				%s0 = memref.load %v6[%arg0, %zero] : memref<16x1xf32>
				%s1 = memref.load %v6[%arg0, %zero] : memref<16x1xf32>
				%s2 = arith.mulf %s0, %s1 : f32 
				memref.store %s2, %v7[%arg0, %zero] : memref<16x1xf32>
			}
		}

		%v8 = memref.alloc() : memref<16x1xf32>
		affine.for %arg0 = 0 to 16 {
			affine.for %arg1 = 0 to 1 {
				%s = arith.constant 1.0 : f32
				memref.store %s, %v8[%arg0, %zero] : memref<16x1xf32>
			}
		}

		%v9 = memref.alloc() : memref<16x1xf32>
		affine.for %arg0 = 0 to 16 {
			affine.for %arg1 = 0 to 1 {
				%s0 = memref.load %v8[%arg0, %zero] : memref<16x1xf32>
				%s1 = memref.load %v6[%arg0, %zero] : memref<16x1xf32>
				%s2 = arith.mulf %s0, %s1 : f32 
				memref.store %s2, %v9[%arg0, %zero] : memref<16x1xf32>
			}
		}

		%v10 = memref.alloc() : memref<16x1xf32>
		affine.for %arg0 = 0 to 16 {
			affine.for %arg1 = 0 to 1 {
				%s0 = memref.load %v8[%arg0, %zero] : memref<16x1xf32>
				%s1 = memref.load %v6[%arg0, %zero] : memref<16x1xf32>
				%s2 = arith.mulf %s0, %s1 : f32 
				memref.store %s2, %v10[%arg0, %zero] : memref<16x1xf32>
			}
		}

		%v11 = memref.alloc() : memref<16x1xf32>
		affine.for %arg0 = 0 to 16 {
			affine.for %arg1 = 0 to 1 {
				%s0 = memref.load %v9[%arg0, %zero] : memref<16x1xf32>
				%s1 = memref.load %v10[%arg0, %zero] : memref<16x1xf32>
				%s2 = arith.addf %s0, %s1 : f32 
				memref.store %s2, %v11[%arg0, %zero] : memref<16x1xf32>
			}
		}

		%v12 = memref.alloc() : memref<16x1xf32>
		affine.for %arg0 = 0 to 16 {
			affine.for %arg1 = 0 to 1 {
				%s_zero = arith.constant 0.0 : f32
				%s0 = memref.load %v11[%arg0, %zero] : memref<16x1xf32>
				%s1 = arith.subf %s_zero, %s0 : f32
				memref.store %s1, %v12[%arg0, %zero] : memref<16x1xf32>
			}
		}

		%v13 = memref.alloc() : memref<1x1xf32>
		// FIXME: reshape is not implemented. Coming soon
		affine.for %arg0 = 0 to 1 {
			affine.for %arg1 = 0 to 1 {
				%s_zero = arith.constant 0.0 : f32
				memref.store %s_zero, %v13[%zero, %zero] : memref<1x1xf32>
			}
		}
		affine.for %arg0 = 0 to 16 {
			affine.for %arg1 = 0 to 1 {
				%s0 = memref.load %v13[%zero, %zero] : memref<1x1xf32>
				%s1 = memref.load %v11[%arg0, %zero] : memref<16x1xf32>
				%s2 = arith.addf %s0, %s1 : f32
				memref.store %s2, %v13[%zero, %zero] : memref<1x1xf32>
			}
		}

		%v14 = memref.alloc() : memref<1x10xf32>
		affine.for %arg0 = 0 to 10 {
			affine.for %arg1 = 0 to 1 {
				%s = memref.load %v0[%arg0, %arg1] : memref<10x1xf32>
				memref.store %s, %v14[%arg1, %arg0] : memref<1x10xf32>
			}
		}

		%v15 = memref.alloc() : memref<16x10xf32>
		affine.for %arg0 = 0 to 16 {
			affine.for %arg1 = 0 to 10 {
				%s5 = arith.constant 0.0 : f32
				memref.store %s5, %v15[%arg0, %arg1] : memref<16x10xf32>
				affine.for %arg2 = 0 to 1 {
					%s0 = memref.load %v15[%arg0, %arg1] : memref<16x10xf32>
					%s1 = memref.load %v11[%arg0, %arg2] : memref<16x1xf32>
					%s2 = memref.load %v14[%arg2, %arg1] : memref<1x10xf32>
					%s3 = arith.mulf %s1, %s2 : f32
					%s4 = arith.addf %s0, %s3 : f32
					memref.store %s4, %v15[%arg0, %arg1] : memref<16x10xf32>
				}
			}
		}

		%v16 = memref.alloc() : memref<10x16xf32>
		affine.for %arg0 = 0 to 16 {
			affine.for %arg1 = 0 to 10 {
				%s = memref.load %v2[%arg0, %arg1] : memref<16x10xf32>
				memref.store %s, %v16[%arg1, %arg0] : memref<10x16xf32>
			}
		}

		%v17 = memref.alloc() : memref<10x1xf32>
		affine.for %arg0 = 0 to 10 {
			affine.for %arg1 = 0 to 1 {
				%s5 = arith.constant 0.0 : f32
				memref.store %s5, %v17[%arg0, %arg1] : memref<10x1xf32>
				affine.for %arg2 = 0 to 16 {
					%s0 = memref.load %v17[%arg0, %arg1] : memref<10x1xf32>
					%s1 = memref.load %v16[%arg0, %arg2] : memref<10x16xf32>
					%s2 = memref.load %v11[%arg2, %arg1] : memref<16x1xf32>
					%s3 = arith.mulf %s1, %s2 : f32
					%s4 = arith.addf %s0, %s3 : f32
					memref.store %s4, %v17[%arg0, %arg1] : memref<10x1xf32>
				}
			}
		}

		%v18 = memref.alloc() : memref<16x1xf32>
		affine.for %arg0 = 0 to 16 {
			affine.for %arg1 = 0 to 1 {
				%s0 = memref.load %v11[%arg0, %zero] : memref<16x1xf32>
				%s1 = memref.load %v11[%arg0, %zero] : memref<16x1xf32>
				%s2 = arith.addf %s0, %s1 : f32 
				memref.store %s2, %v18[%arg0, %zero] : memref<16x1xf32>
			}
		}

		%v19 = memref.alloc() : memref<16x1xf32>
		affine.for %arg0 = 0 to 16 {
			affine.for %arg1 = 0 to 1 {
				%s_zero = arith.constant 0.0 : f32
				%s0 = memref.load %v11[%arg0, %zero] : memref<16x1xf32>
				%s1 = arith.subf %s_zero, %s0 : f32
				memref.store %s1, %v19[%arg0, %zero] : memref<16x1xf32>
			}
		}

		%v20 = memref.alloc() : memref<16x1xf32>
		affine.for %arg0 = 0 to 16 {
			affine.for %arg1 = 0 to 1 {
				%s0 = memref.load %v12[%arg0, %zero] : memref<16x1xf32>
				%s1 = memref.load %v19[%arg0, %zero] : memref<16x1xf32>
				%s2 = arith.addf %s0, %s1 : f32 
				memref.store %s2, %v20[%arg0, %zero] : memref<16x1xf32>
			}
		}

		%v21 = memref.alloc() : memref<16x1xf32>
		affine.for %arg0 = 0 to 16 {
			affine.for %arg1 = 0 to 1 {
				%s0 = memref.load %v11[%arg0, %zero] : memref<16x1xf32>
				%s1 = memref.load %v18[%arg0, %zero] : memref<16x1xf32>
				%s2 = arith.addf %s0, %s1 : f32 
				memref.store %s2, %v21[%arg0, %zero] : memref<16x1xf32>
			}
		}

		%v22 = memref.alloc() : memref<1x1xf32>
		// FIXME: reshape is not implemented. Coming soon
		affine.for %arg0 = 0 to 1 {
			affine.for %arg1 = 0 to 1 {
				%s_zero = arith.constant 0.0 : f32
				memref.store %s_zero, %v22[%zero, %zero] : memref<1x1xf32>
			}
		}
		affine.for %arg0 = 0 to 16 {
			affine.for %arg1 = 0 to 1 {
				%s0 = memref.load %v22[%zero, %zero] : memref<1x1xf32>
				%s1 = memref.load %v18[%arg0, %zero] : memref<16x1xf32>
				%s2 = arith.addf %s0, %s1 : f32
				memref.store %s2, %v22[%zero, %zero] : memref<1x1xf32>
			}
		}

		%v23 = memref.alloc() : memref<1x1xf32>
		affine.for %arg0 = 0 to 1 {
			affine.for %arg1 = 0 to 1 {
				%s0 = memref.load %v13[%zero, %zero] : memref<1x1xf32>
				%s1 = memref.load %v22[%zero, %zero] : memref<1x1xf32>
				%s2 = arith.addf %s0, %s1 : f32 
				memref.store %s2, %v23[%zero, %zero] : memref<1x1xf32>
			}
		}

		%v24 = memref.alloc() : memref<1x10xf32>
		affine.for %arg0 = 0 to 10 {
			affine.for %arg1 = 0 to 1 {
				%s = memref.load %v0[%arg0, %arg1] : memref<10x1xf32>
				memref.store %s, %v24[%arg1, %arg0] : memref<1x10xf32>
			}
		}

		%v25 = memref.alloc() : memref<16x10xf32>
		affine.for %arg0 = 0 to 16 {
			affine.for %arg1 = 0 to 10 {
				%s5 = arith.constant 0.0 : f32
				memref.store %s5, %v25[%arg0, %arg1] : memref<16x10xf32>
				affine.for %arg2 = 0 to 1 {
					%s0 = memref.load %v25[%arg0, %arg1] : memref<16x10xf32>
					%s1 = memref.load %v21[%arg0, %arg2] : memref<16x1xf32>
					%s2 = memref.load %v24[%arg2, %arg1] : memref<1x10xf32>
					%s3 = arith.mulf %s1, %s2 : f32
					%s4 = arith.addf %s0, %s3 : f32
					memref.store %s4, %v25[%arg0, %arg1] : memref<16x10xf32>
				}
			}
		}

		%v26 = memref.alloc() : memref<16x10xf32>
		affine.for %arg0 = 0 to 16 {
			affine.for %arg1 = 0 to 10 {
				%s0 = memref.load %v15[%arg0, %arg1] : memref<16x10xf32>
				%s1 = memref.load %v25[%arg0, %arg1] : memref<16x10xf32>
				%s2 = arith.addf %s0, %s1 : f32 
				memref.store %s2, %v26[%arg0, %arg1] : memref<16x10xf32>
			}
		}

		%v27 = memref.alloc() : memref<10x16xf32>
		affine.for %arg0 = 0 to 16 {
			affine.for %arg1 = 0 to 10 {
				%s = memref.load %v2[%arg0, %arg1] : memref<16x10xf32>
				memref.store %s, %v27[%arg1, %arg0] : memref<10x16xf32>
			}
		}

		%v28 = memref.alloc() : memref<10x1xf32>
		affine.for %arg0 = 0 to 10 {
			affine.for %arg1 = 0 to 1 {
				%s5 = arith.constant 0.0 : f32
				memref.store %s5, %v28[%arg0, %arg1] : memref<10x1xf32>
				affine.for %arg2 = 0 to 16 {
					%s0 = memref.load %v28[%arg0, %arg1] : memref<10x1xf32>
					%s1 = memref.load %v27[%arg0, %arg2] : memref<10x16xf32>
					%s2 = memref.load %v21[%arg2, %arg1] : memref<16x1xf32>
					%s3 = arith.mulf %s1, %s2 : f32
					%s4 = arith.addf %s0, %s3 : f32
					memref.store %s4, %v28[%arg0, %arg1] : memref<10x1xf32>
				}
			}
		}

		%v29 = memref.alloc() : memref<10x1xf32>
		affine.for %arg0 = 0 to 10 {
			affine.for %arg1 = 0 to 1 {
				%s0 = memref.load %v17[%arg0, %zero] : memref<10x1xf32>
				%s1 = memref.load %v28[%arg0, %zero] : memref<10x1xf32>
				%s2 = arith.addf %s0, %s1 : f32 
				memref.store %s2, %v29[%arg0, %zero] : memref<10x1xf32>
			}
		}

		return %v29, %v23 : memref<10x1xf32>, memref<1x1xf32>

	}
}
